# ğŸ”¥ PySpark Learning Lab

Welcome to your fully Dockerized, Spark-enabled Python environment designed for hands-on data processing, analytics, and machine learning with PySpark.

---

## ğŸš€ Project Features

- ğŸ³ **Docker-based** development environment using VSCode Dev Containers
- ğŸ”¥ **Apache Spark 3.5.5** installed with Java 17
- ğŸ“Š **Jupyter Lab** auto-launching inside container (on port `8888`)
- ğŸ§ª **PySpark** pre-installed and ready to run
- âš¡ Uses `uv` for ultrafast pip installations
- ğŸ§  Dev-friendly: linting, autocomplete, notebooks, and Python terminal

---

## ğŸ“ Project Structure

pyspark-learning/ â”œâ”€â”€ notebooks/ # Jupyter Notebooks for lessons & experiments â”œâ”€â”€ scripts/ # PySpark Python scripts â”œâ”€â”€ data/ # Sample datasets (CSV, JSON, Parquet) â”œâ”€â”€ .devcontainer/ # Docker + VSCode config â”‚ â”œâ”€â”€ Dockerfile â”‚ â””â”€â”€ devcontainer.json â”œâ”€â”€ requirements.txt # Python dependencies â””â”€â”€ README.md # You're reading it


---

## ğŸ› ï¸ Getting Started

### ğŸ§³ Prerequisites
- Docker
- Visual Studio Code
- Dev Containers extension installed

### ğŸ§ª Launch Environment

```bash
git clone https://github.com/YOUR_USERNAME/pyspark-learning.git
cd pyspark-learning
# Open in VSCode and select "Reopen in Container" when prompted

ğŸ“š Lessons Available
âœ… Lesson 1: SparkSession + DataFrames

ğŸ”œ Lesson 2: Reading CSVs & transforming external data

ğŸ”œ Lesson 3: Writing Parquet + Performance tips

ğŸ”œ Lesson 4: Data Aggregation and Joins

ğŸ”œ Lesson 5: ML with PySpark

ğŸ¤ Contributing
Feel free to fork and submit PRs with additional lessons, improvements, or data sets. This repo is intended as a learning lab for aspiring Spark + Python engineers.

ğŸ“œ License
MIT License â€” do whatever you want, just donâ€™t blame me ğŸ˜„